import streamlit as st
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from imblearn.over_sampling import RandomOverSampler  # ROS iÃ§in gerekli kÃ¼tÃ¼phane
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import StratifiedKFold
# from sklearn.model_selection import train_test_split, cross_val_score

st.title("ğŸ› ï¸ Model EÄŸitimi")

# Burda local storage ye ekledklerimzi Ã§ekiyoruz.
if 'data' in st.session_state and 'target_column' in st.session_state:
    data = st.session_state['data']
    target_column = st.session_state['target_column']

    # Model seÃ§imi
    model_choice = st.selectbox("Model SeÃ§in:", ["Random Forest", "Logistic Regression", "SVM"])
    model = None
    if model_choice == "Random Forest":
        model = RandomForestClassifier()
    elif model_choice == "Logistic Regression":
        model = LogisticRegression()
    else:
        # probalitiy true olayÄ± normalde svm etiket dÃ¶ndÃ¼r. Ancak bÃ¶yle yapÄ±nca olasÄ±lÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼rttÃ¼rÃ¼yoruz.
        model = SVC(probability=True) 

    handle_imbalance = st.checkbox("Dengesizlikle baÅŸa Ã§Ä±k (ROS uygula)")


    # Modeli eÄŸit butonuna basÄ±ldÄ±ysa
    if st.button("Modeli EÄŸit"):
        data = st.session_state['data']

        # Veri bÃ¶lme
        # .drop ile istemediklerimizi kaldÄ±rÄ±rÄ±z. Burdada outcome'Ä± kaldÄ±rÄ±yoruz mesela gerisini alÄ±yoruz. 
        X = data.drop(columns=[target_column])
        y = data[target_column]
        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # StratifiedKFold nesnesi oluÅŸtur
        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

        # SkorlarÄ± ve veri kÃ¼melerini saklamak iÃ§in deÄŸiÅŸkenler
        best_score = -np.inf # En iyi skorun baÅŸlangÄ±Ã§ deÄŸeri -sonsuz
        best_X_train, best_X_test = None, None
        best_y_train, best_y_test = None, None
        cv_scores = []
        fold = 0
        # Her bir fold iÃ§in model eÄŸitimi ve deÄŸerlendirme
        for train_index, test_index in skf.split(X, y):
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            fold += 1
            # train_index te tÃ¼m ayrÄ±lmÄ±ÅŸ satÄ±r indexleri var. Yani %80 lik kÄ±sÄ±m

            # Modeli eÄŸit ve tahmin yap

            if handle_imbalance:
                st.info(f"Fold : {fold} iÃ§in dengesizlikle baÅŸa Ã§Ä±kÄ±lÄ±yor... (ROS)")
                ros = RandomOverSampler(random_state=42)  # random state vermemizin sebebi her seferinde aynÄ± sonucu almak. BÃ¶yle olunca random olmaz. Modelin tek bir sonucu olur.
                X_train, y_train = ros.fit_resample(X_train, y_train)
                
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            # Her bir foldun performans analizi iÃ§in y_test ve y_pred'i saklÄ±yoruz.
            st.session_state[f'y_test_{fold}'] = y_test
            st.session_state[f'y_pred_{fold}'] = y_pred

            # Skoru hesapla
            score = accuracy_score(y_test, y_pred)
            cv_scores.append(score)

            print(f"Fold Skoru: {score:.4f}")

            # En iyi skoru kontrol et ve gÃ¼ncelle
            if score > best_score:
                best_score = score
                best_X_train, best_X_test = X_train, X_test
                best_y_train, best_y_test = y_train, y_test
        # Performans verileri kaydediliyor
                st.session_state['model'] = model
                st.session_state['y_test'] = best_y_test
                st.session_state['y_pred'] = y_pred
                st.session_state['cv_scores'] = cv_scores  

        st.success("Model eÄŸitildi ve metrikler hesaplandÄ±!")
        st.write("ğŸ“Š K-Fold CV SkorlarÄ±:")
        st.write(cv_scores)


else:
    st.warning("LÃ¼tfen Ã¶nce veri yÃ¼kleyin ve hedef kolonu seÃ§in!")



  # x train : outcome hariicindeki o %80 lik seÃ§ilen sÃ¼tun
        # x test : outcome haricindeki o ayrÄ±lan % 20 lu kÄ±sÄ±m 
        # y train : outcome inin %80 lik kÄ±smÄ± yani Ã¼stteki xtrainin sonuÃ§larÄ± gibi dÃ¼ÅŸÃ¼nebilirz.
        # y test :  outcome nin %20 luk kÄ±smÄ± bh da Ã¼stteki xtesttin sonuÃ§karÄ± gibi dÃ¼ÅŸÃ¼nebiliriz.

  # cv_scores = cross_val_score(model, X_train, y_train, cv=5)
         # Burda normalde tÃ¼m veri setini vermemiz gerekir K folda. Benim verememim sebebi ise amacÄ±m gizli bir validation set oluÅŸturmak. bunun skorunu alÄ±yoruz. BÃ¶ylelikle test seti Ã¼zerinde doÄŸru bir tahmin yapmÄ±ÅŸ oluyoruz. Yani overfittingten kaÃ§Ä±yorum. Ancak bu durumda underfitting yaÅŸasaydÄ±m yani skorum dÃ¼ÅŸÃ¼k Ã§Ä±ksaydÄ± bu durumda tÃ¼m veri setini verip modeli eÄŸitmek daha mantÄ±klÄ± olurdu.

        # Model eÄŸitimi ve tahmin
        # model.fit(best_X_train, best_y_train)
        # best_y_pred = model.predict(best_X_test)
