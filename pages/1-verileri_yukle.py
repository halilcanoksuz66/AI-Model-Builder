import streamlit as st
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import numpy as np


st.title("ğŸ“‚ Veri YÃ¼kleme")
uploaded_file = st.file_uploader("Veri setinizi yÃ¼kleyin (CSV formatÄ±nda):")

if uploaded_file is not None:
    try:
        data = pd.read_csv(uploaded_file)
        
        # Veri Ã§erÃ§evesinin boÅŸ olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        if data.empty:
            st.error("YÃ¼klenen dosya boÅŸ. LÃ¼tfen geÃ§erli bir CSV dosyasÄ± yÃ¼kleyin.")
        else:
            # Veriyi session_state'e kaydet. Javascript Local Storage gibi dÃ¼ÅŸÃ¼nebiliriz.
            st.session_state['data'] = data
            
            # YÃ¼klenen veri setinin ilk 5 satÄ±rÄ±nÄ± gÃ¶sterir.
            st.write("YÃ¼klenen Veri:")
            st.write(data.head())


            # Hedef kolonu seÃ§me
            target_column = st.selectbox("Hedef Kolon:", data.columns)
            st.session_state['target_column'] = target_column
            
           
            # Eksik deÄŸer kontrolÃ¼
            if data.isnull().sum().sum() > 0:
                st.write("ğŸ§ Eksik DeÄŸer KontrolÃ¼:")
                st.write(data.isnull().sum())
                missing_values_option = st.radio("Eksik deÄŸerleri doldurmak ister misiniz?", ["HayÄ±r", "Ortalama ile doldur", "Medyan ile doldur", "Mod ile doldur"])

                if missing_values_option != "HayÄ±r":
                    try:
                        if missing_values_option == "Ortalama ile doldur":
                            data = data.fillna(data.mean())
                        elif missing_values_option == "Medyan ile doldur":
                            data = data.fillna(data.median())
                        elif missing_values_option == "Mod ile doldur":
                            data = data.fillna(data.mode().iloc[0])

                        # mean() fonksiyonu eksik deÄŸerleri doldururken ortalama deÄŸeri kullanÄ±r.
                        # mode() fonksiyonu eksik deÄŸerleri doldururken en sÄ±k tekrar eden deÄŸeri kullanÄ±r. iloc[0] ile ilk deÄŸeri alÄ±rÄ±z.
                        # median() fonksiyonu eksik deÄŸerleri doldururken verilerin sÄ±ralanmÄ±ÅŸ ÅŸekilde ortanca deÄŸeri kullanÄ±r.
                        # Eksik deÄŸerleri doldurulmuÅŸ veriyi session_state'e kaydet
                        st.session_state['data'] = data
                        st.success("Eksik deÄŸerler baÅŸarÄ±yla dolduruldu!")
                        st.write("Eksik DeÄŸerleri DoldurulmuÅŸ Veri:")
                        st.write(data.head())
                    except Exception as e:
                        st.error(f"Hata oluÅŸtu: {e}")


            # AykÄ±rÄ± deÄŸerleri tespit ve Ã§Ä±karma
            def detect_and_remove_outliers(df, threshold=3):
                # StandardScaler kullanarak veriyi standardize et (Z-skoru hesapla)
                # threshold deÄŸeri 3 olarak vermemin sebebi verilerin %99.7'sinin -3 ve +3 arasÄ±nda olmasÄ±dÄ±r.
                scaler = StandardScaler()
                z_scores = np.abs(scaler.fit_transform(df))
                
                # Z-skoru > threshold olanlarÄ± Ã§Ä±kar .all(axis=1) tÃ¼m satÄ±rlarÄ± kontrol eder.
                df_cleaned = df[(z_scores < threshold).all(axis=1)]
                
                # EÄŸer aykÄ±rÄ± deÄŸerler varsa kullanÄ±cÄ±yÄ± bilgilendir
                if len(df) != len(df_cleaned):
                    st.success(f"AykÄ±rÄ± deÄŸerler tespit edildi ve {len(df) - len(df_cleaned)} satÄ±r Ã§Ä±karÄ±ldÄ±.")
                else:
                    st.success("AykÄ±rÄ± deÄŸer bulunmadÄ±.")

                return df_cleaned

            # AykÄ±rÄ± deÄŸerleri temizleme seÃ§eneÄŸi
            remove_outliers = st.radio("AykÄ±rÄ± deÄŸerleri temizlemek ister misiniz?", ["HayÄ±r", "Evet"])
            if remove_outliers == "Evet":
                try:
                    feature_columns = [col for col in data.columns if col != target_column]
                    print(feature_columns)
                    data_cleaned = detect_and_remove_outliers(data) 

                    # AykÄ±rÄ± deÄŸerleri temizlenmiÅŸ veriyi session_state'e kaydet
                    st.session_state['data'] = data_cleaned
                    st.write("AykÄ±rÄ± DeÄŸerleri TemizlenmiÅŸ Veri:")
                    st.write(data_cleaned.head())
                except Exception as e:
                    st.error(f"Hata oluÅŸtu: {e}")



            # Veriyi normalleÅŸtirme seÃ§eneÄŸi
            normalization_method = st.radio("Veriyi normalleÅŸtirmek ister misiniz?", ["HayÄ±r", "Min-Max", "Z-Skoru (Standard Scaler)"])

            if normalization_method != "HayÄ±r":
                try:
                    scaler = None
                    if normalization_method == "Min-Max":
                        scaler = MinMaxScaler()
                    elif normalization_method == "Z-Skoru (Standard Scaler)":
                        scaler = StandardScaler()

                    feature_columns = [col for col in data.columns if col != target_column]
                    data_normalized = data.copy()
                    data_normalized[feature_columns] = scaler.fit_transform(data[feature_columns])

                    # NormalleÅŸtirilmiÅŸ veriyi session_state'e kaydet
                    st.session_state['data'] = data_normalized
                    st.success("Normalizasyon baÅŸarÄ±yla uygulandÄ±!")
                    st.write("NormalleÅŸtirilmiÅŸ Veri:")
                    st.write(data_normalized.head())
                except Exception as e:
                    st.error(f"Hata oluÅŸtu: {e}")

             

    except Exception as e:
        st.error(f"Hata oluÅŸtu: {e}. LÃ¼tfen CSV formatÄ±nda geÃ§erli bir dosya yÃ¼kleyin.")
else:
    st.info("LÃ¼tfen bir dosya yÃ¼kleyin.")
